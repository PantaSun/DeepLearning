{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度检查\n",
    "#### 两种梯度\n",
    "设有一个函数$f(x)$， 则该函数在x处的梯度可以有两种计算方法：\n",
    "- 数值计算梯度（numerical gradient）：其数学定义为$$\\frac{df(x)}{{dx }} = \\mathop {\\lim }\\limits_{h  \\to 0} \\frac{{f(x  + h ) - f(x  - h )}}{{2h }}$$ 这里的h是一个很小的数字，在实践中近似为1e-5。数值计算梯度的优点是容易编程实现，不用要求f(x)必须是可微的，但是数值计算梯度的缺点也很明显：*求解速度慢，且得到的结果通常是近似解*，因此在设计机器学习的目标（损失）函数时，一般不用这种方法而是使用解析梯度。\n",
    "- 解析梯度（analytic gradient）：是通过求导公式直接求出来的，也就是要把目标函数设计成可微的函数。这种方法可以快速求出梯度，而且这个梯度是确切值。\n",
    "  \n",
    "#### 为什么要做梯度检查？\n",
    "神经网络在使用反向传播计算目标函数关于每个参数的梯度（即解析梯度）时，由于计算过程中涉及的参数很多，于是计算很容易出错，最终会导致出现很差的参数值。为了确认代码中反向传播计算的梯度是否正确，可以采用梯度检查的方法。\n",
    "#### 如何做\n",
    "**使用相对误差来比较**：设数值梯度为$f_n^{'}$，解析梯度为$f_a^{'}$则相对误差为：$$\\frac{|f_{a}^{'} - f_{n}^{'}|}{max(|f_{a}^{'}|,|f_{n}^{'}|)}$$\n",
    "在实践中：\n",
    "\n",
    "- 相对误差>1e-2：通常就意味着梯度可能出错。\n",
    "\n",
    "- 1e-2>相对误差>1e-4：要对这个值感到不舒服才行。\n",
    "\n",
    "- 1e-4>相对误差：这个值的相对误差对于有不可导点的目标函数是OK的。但如果目标函数中没有kink（使用tanh和softmax），那么相对误差值还是太高。\n",
    "\n",
    "- 1e-7或者更小：好结果，可以高兴一把了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.80476247e-13, 9.42771324e-13, 1.57937155e-13])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "f = lambda x: 1.0/(1 + np.exp(-x))\n",
    "\n",
    "def analytic_gradient(x, f):\n",
    "    return (1 - f(x)) * f(x)\n",
    "\n",
    "def numerical_gradient(x, f, h):\n",
    "    return (f(x + h) - f(x - h)) / (2 * h)\n",
    "\n",
    "def gradient_check(ag, ng):\n",
    "    return abs(ag - ng) / np.array([max(abs(aaa)[i], abs(bbb)[i]) for i in range(len(aaa))])\n",
    "\n",
    "\n",
    "x0 = np.array([1, 2, 3])\n",
    "h = 1e-5\n",
    "ag = analytic_gradient(x0, f)\n",
    "ng = numerical_gradient(x0, f, h)\n",
    "gradient_check(ag, ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 7]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[max(abs(aaa)[i], abs(bbb)[i]) for i in range(len(aaa))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
